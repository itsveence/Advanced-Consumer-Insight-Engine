{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca4a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "###Page title Page not found\n",
    "\n",
    "# Read the Excel file and load the URL column\n",
    "df = pd.read_excel('amostra.xlsx')\n",
    "url_column = 'url_product'  \n",
    "\n",
    "# Create a new column for the feedback\n",
    "df['Feedback'] = ''\n",
    "\n",
    "# Iterate over each URL in the column\n",
    "for index, url in enumerate(df[url_column]):\n",
    "    try:\n",
    "        # Send a GET request to the URL\n",
    "        \n",
    "        h = {\n",
    "          \"Cache-Control\": \"no-cache\",\n",
    "          \"Pragma\": \"no-cache\", \n",
    "          'User-Agent': 'https://developers.whatismybrowser.com/useragents/parse/1274624safari-macos-webkit'\n",
    "        }\n",
    "        response = requests.get(url, headers= h)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        \n",
    "        # Find the <title> tag within the <head> section\n",
    "        title_tag = soup.head.title\n",
    "        #\n",
    "        #print(url, title_tag, soup)\n",
    "        if title_tag == None:\n",
    "            title_tag = \"\"\n",
    "        else: \n",
    "            title_tag = title_tag.text\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        # Check if the <title> tag contains \"Page Not Found\"\n",
    "        if \"Page Not Found\" in title_tag:\n",
    "            df.at[index, 'Feedback'] = 'yes'\n",
    "            print(f'Found \"Page Not Found\" in the title tag of the page: {url}')\n",
    "        else:\n",
    "            df.at[index, 'Feedback'] = 'no'\n",
    "            print(f'\"Page found!\" in the title tag of the page: {url}')\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        df.at[index, 'Feedback'] = 'error'\n",
    "        print(f'Error accessing URL: {url}')\n",
    "        print(e)\n",
    "\n",
    "# Save the updated DataFrame to a new Excel file\n",
    "df.to_excel('pagenotfound1.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f14e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "###Page title Page not found\n",
    "\n",
    "# Read the Excel file and load the URL column\n",
    "df = pd.read_excel('prevtest2_1_st_brand_28_04.xlsx')\n",
    "url_column = 'url_product'  \n",
    "\n",
    "# Create a new column for the feedback\n",
    "df['Feedback'] = ''\n",
    "\n",
    "# Iterate over each URL in the column\n",
    "for index, url in enumerate(df[url_column]):\n",
    "    try:\n",
    "        # Send a GET request to the URL\n",
    "        \n",
    "        h = {\n",
    "          \"Cache-Control\": \"no-cache\",\n",
    "          \"Pragma\": \"no-cache\", \n",
    "          'User-Agent': 'https://developers.whatismybrowser.com/useragents/parse/1274624safari-macos-webkit'\n",
    "        }\n",
    "        response = requests.get(url, headers= h)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        \n",
    "        # Find the <title> tag within the <head> section\n",
    "        title_tag = soup.head.title\n",
    "        #\n",
    "        #print(url, title_tag, soup)\n",
    "        if title_tag == None:\n",
    "            title_tag = \"\"\n",
    "        else: \n",
    "            title_tag = title_tag.text\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        # Check if the <title> tag contains \"Page Not Found\"\n",
    "        if \"Page Not Found\" in title_tag:\n",
    "            df.at[index, 'Feedback'] = 'yes'\n",
    "            print(f'Found \"Page Not Found\" in the title tag of the page: {url}')\n",
    "        else:\n",
    "            df.at[index, 'Feedback'] = 'no'\n",
    "            print(f'\"Page found!\" in the title tag of the page: {url}')\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        df.at[index, 'Feedback'] = 'error'\n",
    "        print(f'Error accessing URL: {url}')\n",
    "        print(e)\n",
    "\n",
    "# Save the updated DataFrame to a new Excel file\n",
    "df.to_excel('todospagenotfound1.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac910e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "###Image Tag Sorry! We couldn't find that page. Try searching or go to Amazon's home page.\n",
    "\n",
    "# Read the Excel file and load the URL column\n",
    "df = pd.read_excel('amostra.xlsx')\n",
    "url_column = 'url_product'  \n",
    "\n",
    "# Create a new column for the feedback\n",
    "df['Feedback'] = ''\n",
    "\n",
    "# Iterate over each URL in the column\n",
    "for index, url in enumerate(df[url_column]):\n",
    "    try:\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find all <img> tags and check their alt attribute\n",
    "        img_tags = soup.find_all('img')\n",
    "        found = False\n",
    "        for img_tag in img_tags:\n",
    "            if img_tag.get('alt') == \"Sorry! We couldn\\'t find that page. Try searching or go to Amazon\\'s home page.\":\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        # Set the feedback based on the result\n",
    "        if found:\n",
    "            df.at[index, 'Feedback'] = 'yes'\n",
    "            print(f'Found image with alt attribute \"Sorry! We couldn\\'t find that page. Try searching or go to Amazon\\'s home page.\" on the page: {url}')\n",
    "        else:\n",
    "            df.at[index, 'Feedback'] = 'no'\n",
    "            print(f'Image with alt attribute \"Sorry! We couldn\\'t find that page. Try searching or go to Amazon\\'s home page.\" not found on the page: {url}')\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        df.at[index, 'Feedback'] = 'error'\n",
    "        print(f'Error accessing URL: {url}')\n",
    "        print(e)\n",
    "\n",
    "# Save the updated DataFrame to a new Excel file\n",
    "df.to_excel('pagenotfound2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cca14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "### Image scr https://images-na.ssl-images-amazon.com/images/G/01/error/en_US/title._TTD_.png\n",
    "\n",
    "# Read the Excel file and load the URL column\n",
    "df = pd.read_excel('amostra.xlsx')\n",
    "url_column = 'url_product'  # Replace 'column_name' with the actual column name in your Excel file\n",
    "\n",
    "# Create a new column for the feedback\n",
    "df['Feedback'] = ''\n",
    "\n",
    "# Iterate over each URL in the column\n",
    "for index, url in enumerate(df[url_column]):\n",
    "    try:\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find the <img> tag with the desired src attribute and alt text\n",
    "        img_tag = soup.find('img', src='https://images-na.ssl-images-amazon.com/images/G/01/error/en_US/title._TTD_.png', alt=\"Sorry! We couldn't find that page. Try searching or go to Amazon's home page.\")\n",
    "\n",
    "        # Set the feedback based on the result\n",
    "        if img_tag:\n",
    "            df.at[index, 'Feedback'] = 'yes'\n",
    "            print(f'Found image with src \"https://images-na.ssl-images-amazon.com/images/G/01/error/en_US/title._TTD_.png\" on the page: {url}')\n",
    "        else:\n",
    "            df.at[index, 'Feedback'] = 'no'\n",
    "            print(f'Image with src \"https://images-na.ssl-images-amazon.com/images/G/01/error/en_US/title._TTD_.png\" not found on the page: {url}')\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        df.at[index, 'Feedback'] = 'error'\n",
    "        print(f'Error accessing URL: {url}')\n",
    "        print(e)\n",
    "\n",
    "# Save the updated DataFrame to a new Excel file\n",
    "df.to_excel('pagenotfound3.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372cc68c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
